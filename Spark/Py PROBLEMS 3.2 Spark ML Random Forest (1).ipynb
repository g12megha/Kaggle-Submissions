{"cells":[{"cell_type":"markdown","source":["# Spark ML\n#### Dataset Introduction\nThis is a popular dataset for classification. Given a feature vector of 14 census results, the problem is to predict whether a persons income is greater than 50K."],"metadata":{}},{"cell_type":"markdown","source":["#### Open Files (use traindata to train, testdata to test)"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.mount(\"s3a://\"+\"AKIAJH57T\"+\"SADMXPN\"+\"3NWA:cl7ON3wPVCf\"+\"a42eAzHjRD\"+\"v0iVJgsApuS\"+\"H3qwyMwF\"+\"@mlonspark\", \"/mnt/mlonspark\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Import SQLContext and data types\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import VectorIndexer\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# sc is an existing SparkContext.\nsqlContext = SQLContext(sc)\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["trainFileRDD = sc.textFile(\"/mnt/mlonspark/adult.traindata.gz\")\ntestFileRDD = sc.textFile(\"/mnt/mlonspark/adult.testdata.gz\")\n\nprint trainFileRDD.take(5)\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["#### Description of Fields\nNote: For all categorial data, the number the number corresponds to a category. I.e. 1 = \"Private\", 2=\"Self-emp-not-inc\" for the workclass (2nd) column.\n\n* 0-age: continuous.\n* 1-workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n* 2-fnlwgt: continuous.\n* 3-education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n* 4-education-num: continuous.\n* 5-marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n* 6-occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n* 7-relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n* 8-race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n* 9-sex: Female, Male.\n* 10-capital-gain: continuous.\n* 11-capital-loss: continuous.\n* 12-hours-per-week: continuous.\n* 13-native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n* 14-income: >50K, <=50K"],"metadata":{}},{"cell_type":"markdown","source":["#### Create a dataframe with the following fields matching the dataset:\nWith quotes: \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"\n\nWithout Quotes: age ,  workclass ,  fnlwgt ,  education ,  education_num ,  marital_status ,  occupation ,  relationship ,  race ,  sex ,  capital_gain ,  capital_loss ,  hours_per_week ,  native_country ,  income \n\n(You'll find the above 2 lines useful when copy/pasting)"],"metadata":{}},{"cell_type":"code","source":["trainFileRDD1 = trainFileRDD.map(lambda x: x.replace(\" \",\"\"))\ntrainFileRDD2 = trainFileRDD1.map(lambda x: x.split(\",\"))\ntrainFileRDD3 = trainFileRDD2.filter(lambda x : len(x) == 15)\ndef strToint(x):\n  try:\n    return int(x)\n  except:\n    return x\ntrainData = trainFileRDD3.map(lambda x :  [strToint(col) for col in x])  \n\ntestFileRDD11 = testFileRDD.map(lambda x: x.replace(\" \",\"\"))\ntestFileRDD1=testFileRDD11.map(lambda x:x[:-1])\ntestFileRDD2 = testFileRDD1.map(lambda x: x.split(\",\"))\ntestFileRDD3 = testFileRDD2.filter(lambda x : len(x) == 15)\ndef strToint(x):\n  try:\n    return int(x)\n  except:\n    return x\ntestData = testFileRDD3.map(lambda x :  [strToint(col) for col in x])"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["trainData.take(5)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["trainDataSchema = spark.createDataFrame(trainData,[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"])\ntestDataSchema = spark.createDataFrame(testData,[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"])\n#trainDataSchema.head(5)\ntestDataSchema.take(5)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["#### Use StringIndexer to encode the \"string\" typed fields (i.e. generate the dataset we used in the Random Forest Section)\nI.e. produce the following two dataframe objects:\n* trainLFDF: is a dataframe of [features: list, label: ]\n* testLFDF: is a dataframe of [features: list, label: int]\n* where feactures is a list of double values, with all string values converted to double values\n\nHint: Create one StringIndexer object for each column to convert from String to double, then use a pipeline to add an array of StringIndexer objects\n\nUse VectorAssembler\n\nLook at here for example of StringIndexer: http://spark.apache.org/docs/latest/ml-features.html#stringindexer\n\nLook at here for example of a Pipeline:\nhttp://spark.apache.org/docs/latest/ml-guide.html#example-pipeline"],"metadata":{}},{"cell_type":"code","source":["display(trainDataSchema)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["trainDataSchema.printSchema"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["trainDataSchema.collect()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["workclassIndexer.fit(trainDataSchema)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["workclassIndexer = StringIndexer().setInputCol(\"workclass\").setOutputCol(\"workclassIndex\")\neducationIndexer = StringIndexer().setInputCol(\"education\").setOutputCol(\"educationIndex\")\nmarital_statusIndexer = StringIndexer().setInputCol(\"marital_status\").setOutputCol(\"marital_statusIndex\")\noccupationIndexer = StringIndexer().setInputCol(\"occupation\").setOutputCol(\"occupationIndex\")\nrelationshipIndexer = StringIndexer().setInputCol(\"relationship\").setOutputCol(\"relationshipIndex\")\nraceIndexer = StringIndexer().setInputCol(\"race\").setOutputCol(\"raceIndex\")\nincomeIndexer = StringIndexer().setInputCol(\"income\").setOutputCol(\"incomeIndex\")\nsexIndexer = StringIndexer().setInputCol(\"sex\").setOutputCol(\"sexIndex\")\nnative_countryIndexer = StringIndexer().setInputCol(\"native_country\").setOutputCol(\"native_countryIndex\")\nfeaturesAssembler = VectorAssembler(inputCols=[\"age\", \"workclassIndex\", \"fnlwgt\", \"educationIndex\", \"education_num\", \"marital_statusIndex\", \"occupationIndex\", \"relationshipIndex\", \"raceIndex\", \"sexIndex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_countryIndex\"],outputCol=\"Features\")\n\npipleline = Pipeline().setStages([workclassIndexer,educationIndexer,marital_statusIndexer,occupationIndexer,relationshipIndexer,raceIndexer,incomeIndexer,sexIndexer,native_countryIndexer,featuresAssembler])\nmodel = pipleline.fit(trainDataSchema)\ntrainDataT = model.transform(trainDataSchema)\ntrainDataTf = trainDataT.select(\"Features\",\"incomeIndex\")\ntestDataTf = model.transform(testDataSchema).select(\"Features\",\"incomeIndex\")\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["testDataTf.collect()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["#### RandomForest\n1. Create another pipeline to train with training dataset RandomForestClassifier (with maxbins=50, numtrees=10, maxdepth=10).\n1. use the model to predict the test dataset\n1. use MulticlassClassificationEvaluator to get the \"precision\" of the model on the test dataset\n\nexample here: http://spark.apache.org/docs/latest/ml-ensembles.html#example-classification"],"metadata":{}},{"cell_type":"code","source":["Rf =  RandomForestClassifier().setLabelCol(\"incomeIndex\").setFeaturesCol(\"Features\").setNumTrees(10).setMaxDepth(10).setMaxBins(50)\npiplelineRf = Pipeline().setStages([Rf])\nmodelRf = piplelineRf.fit(trainDataTf)\npredictions = modelRf.transform(testDataTf)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["display(predictions)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator()\\\n  .setLabelCol(\"incomeIndex\")\\\n  .setPredictionCol(\"prediction\")\\\n  .setMetricName(\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\n\nprint \"Test Error = %5.2f%%\" % ((1.0 - accuracy)*100)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["print(\"megha\")"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23}],"metadata":{"name":"Py PROBLEMS 3.2 Spark ML Random Forest (1)","notebookId":1223168874573781},"nbformat":4,"nbformat_minor":0}
